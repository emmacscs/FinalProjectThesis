{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e25f08a6",
   "metadata": {},
   "source": [
    "IMPORT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd4d4079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (roc_curve,roc_auc_score,classification_report)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "import joblib \n",
    "from sklearn.metrics import classification_report, roc_curve, auc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73a19b5",
   "metadata": {},
   "source": [
    "We use the dataset as obtained from the mathematical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e54fefb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed = \"C:/Users/emmxc/OneDrive/Escritorio/thesis/FinalProjectThesis/MachineLearning/kinetics.csv\"\n",
    "df = pd.read_csv(preprocessed, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11a5cec",
   "metadata": {},
   "source": [
    "For the machine learning model we will use a Random Forest Classifier and XBoost...\n",
    "\n",
    "Because of the big class imbalance (more hyperglycemia episodes) we willl need to adjust the classifier threshold and weights to prioritize hypoglycemia classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc50d5c",
   "metadata": {},
   "source": [
    "FIRST,\n",
    "\n",
    "Make two random forest classifiers and two XGboost models (hyperglycemia and hypoglycemia) to predict the probability of having a risk episode in t minutes from the selected time. These random forests use as input: Glucose, IOB, COB, calories, distance and BPM and as correct result the columns of hyperglycemia and hypoglycemia in t minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1d719f",
   "metadata": {},
   "source": [
    "We want the input of the model to be the attribute of each feature per time step for the last 2 hours t-15,t-30 etc etc. And the output columns of hyperglycemia or hypoglycemia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee56fb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_input_hyper(df):\n",
    "    # --- Parameters ---\n",
    "    features = ['Glucose', 'BPM', 'Distance', 'Calories', 'Insulin on board', 'COB']\n",
    "    window_size = 8   # 2 hours if 15-minute intervals\n",
    "    step_ahead = 1    # 15 minutes ahead\n",
    "    target_label = 'Hyperglycemia'\n",
    "\n",
    "    # --- Sort and prepare target ---\n",
    "    df = df.sort_values('Time').reset_index(drop=True)\n",
    "    df['Glucose_future'] = df['Glucose'].shift(-step_ahead)\n",
    "    df[target_label] = (df['Glucose_future'] > 6.9).astype(int)\n",
    "\n",
    "    # --- Build ML dataset ---\n",
    "    X_rows, y_rows = [], []\n",
    "    for i in range(window_size, len(df) - step_ahead):\n",
    "        window = df.iloc[i - window_size:i][features]\n",
    "        if window.isnull().values.any():\n",
    "            continue\n",
    "        X_rows.append(window.values.flatten())\n",
    "        y_rows.append(df.iloc[i + step_ahead][target_label])\n",
    "\n",
    "    # --- Create DataFrame ---\n",
    "    X_array = np.array(X_rows)\n",
    "    y_array = np.array(y_rows)\n",
    "    column_names = [f\"{feat}_t-{(window_size - j) * 15}min\" for j in range(window_size) for feat in features]\n",
    "\n",
    "    df_hyper = pd.DataFrame(X_array, columns=column_names)\n",
    "    df_hyper['Outcome'] = y_array  # rename to \"Outcome\" for ML functions\n",
    "\n",
    "    print(\"✅ Final dataset shape:\", df_hyper.shape)\n",
    "    return df_hyper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "887ab1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_input_hypo(df):\n",
    "\n",
    "    # --- Parameters ---\n",
    "    features = ['Glucose', 'BPM', 'Distance', 'Calories', 'Insulin on board', 'COB']\n",
    "    window_size = 8   # 2 hours if 15-minute intervals\n",
    "    step_ahead = 1    # 15 minutes ahead\n",
    "    target_label = 'hYPOGLYCEMIA'\n",
    "\n",
    "    # --- Sort and prepare target ---\n",
    "    df = df.sort_values('Time').reset_index(drop=True)\n",
    "    df['Glucose_future'] = df['Glucose'].shift(-step_ahead)\n",
    "    df[target_label] = (df['Glucose_future'] < 3.9).astype(int)\n",
    "\n",
    "    # --- Build ML dataset ---\n",
    "    X_rows, y_rows = [], []\n",
    "    for i in range(window_size, len(df) - step_ahead):\n",
    "        window = df.iloc[i - window_size:i][features]\n",
    "        if window.isnull().values.any():\n",
    "            continue\n",
    "        X_rows.append(window.values.flatten())\n",
    "        y_rows.append(df.iloc[i + step_ahead][target_label])\n",
    "\n",
    "    # --- Create DataFrame ---\n",
    "    X_array = np.array(X_rows)\n",
    "    y_array = np.array(y_rows)\n",
    "    column_names = [f\"{feat}_t-{(window_size - j) * 15}min\" for j in range(window_size) for feat in features]\n",
    "\n",
    "    df_hyper = pd.DataFrame(X_array, columns=column_names)\n",
    "    df_hyper['Outcome'] = y_array  # rename to \"Outcome\" for ML functions\n",
    "\n",
    "    print(\"✅ Final dataset shape:\", df_hyper.shape)\n",
    "    return df_hyper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632cc165",
   "metadata": {},
   "source": [
    "Now we will train and test the RANDOM FOREST FOR HYPERGLYCEMIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "440d96d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict_rf(df_kinetics, features, prediction_minutes=60, interval_minutes=5, glucose_col='Glucose'):\n",
    "    print(f\"\\n⏱ Training Random Forest for {prediction_minutes}-minute ahead prediction...\\n\")\n",
    "    \n",
    "    # Step 1: Setup\n",
    "    future_steps = int(prediction_minutes / interval_minutes)\n",
    "    df = df_kinetics.copy()\n",
    "    \n",
    "    df['Glucose_future'] = df[glucose_col].shift(-future_steps)\n",
    "    df['Hyper'] = (df['Glucose_future'] > 6.9).astype(int)\n",
    "    df['Hypo'] = (df['Glucose_future'] < 3.9).astype(int)\n",
    "\n",
    "    # Step 2: Build rolling feature windows\n",
    "    X_rows, y_hyper, y_hypo = [], [], []\n",
    "    window_size = 1  # only current timepoint\n",
    "    for i in range(len(df) - future_steps):\n",
    "        window = df.iloc[i:i + window_size][features]\n",
    "        if window.isnull().values.any():\n",
    "            continue\n",
    "        X_rows.append(window.values.flatten())\n",
    "        y_hyper.append(df.iloc[i]['Hyper'])\n",
    "        y_hypo.append(df.iloc[i]['Hypo'])\n",
    "\n",
    "    X = np.array(X_rows)\n",
    "    y_hyper = np.array(y_hyper)\n",
    "    y_hypo = np.array(y_hypo)\n",
    "\n",
    "    # Step 3: Preprocessing\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    X_processed = pipeline.fit_transform(X)\n",
    "\n",
    "    # Step 4: Split\n",
    "    X_train_hyper, X_test_hyper, y_train_hyper, y_test_hyper = train_test_split(X_processed, y_hyper, test_size=0.2, random_state=42)\n",
    "    X_train_hypo, X_test_hypo, y_train_hypo, y_test_hypo = train_test_split(X_processed, y_hypo, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Step 5: Train\n",
    "    clf_hyper = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "    clf_hypo = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "\n",
    "    clf_hyper.fit(X_train_hyper, y_train_hyper)\n",
    "    clf_hypo.fit(X_train_hypo, y_train_hypo)\n",
    "\n",
    "    # Step 6: Evaluation\n",
    "    print(\"🔺 Hyperglycemia Report:\")\n",
    "    y_pred_hyper = clf_hyper.predict(X_test_hyper)\n",
    "    y_proba_hyper = clf_hyper.predict_proba(X_test_hyper)[:, 1]\n",
    "    print(classification_report(y_test_hyper, y_pred_hyper))\n",
    "    print(f\"AUC: {roc_auc_score(y_test_hyper, y_proba_hyper):.3f}\\n\")\n",
    "\n",
    "    print(\"🔻 Hypoglycemia Report:\")\n",
    "    y_pred_hypo = clf_hypo.predict(X_test_hypo)\n",
    "    y_proba_hypo = clf_hypo.predict_proba(X_test_hypo)[:, 1]\n",
    "    print(classification_report(y_test_hypo, y_pred_hypo))\n",
    "    print(f\"AUC: {roc_auc_score(y_test_hypo, y_proba_hypo):.3f}\\n\")\n",
    "\n",
    "    # Step 7: Predict from current time\n",
    "    latest = df_kinetics.iloc[[-1]][features]\n",
    "    latest_proc = pipeline.transform(latest.values)\n",
    "\n",
    "    prob_hyper_now = clf_hyper.predict_proba(latest_proc)[0, 1]\n",
    "    prob_hypo_now = clf_hypo.predict_proba(latest_proc)[0, 1]\n",
    "\n",
    "    print(\"📈 Predicted probability at current time:\")\n",
    "    print(f\"  🔺 Hyperglycemia in {prediction_minutes} min: {prob_hyper_now * 100:.2f}%\")\n",
    "    print(f\"  🔻 Hypoglycemia in {prediction_minutes} min: {prob_hypo_now * 100:.2f}%\")\n",
    "\n",
    "    return clf_hyper, clf_hypo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be516d6c",
   "metadata": {},
   "source": [
    "We evaluate models using:\n",
    "\n",
    "Classification Report (precision, recall, F1-score)\n",
    "\n",
    "ROC Curve and AUC Score – show how well the model separates risk/no-risk cases\n",
    "\n",
    "These metrics help us understand whether our model is clinically useful and how confident it is in risk predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7d14c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱ Training Random Forest for 60-minute ahead prediction...\n",
      "\n",
      "🔺 Hyperglycemia Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.56      0.65       209\n",
      "           1       0.75      0.89      0.82       309\n",
      "\n",
      "    accuracy                           0.76       518\n",
      "   macro avg       0.77      0.73      0.73       518\n",
      "weighted avg       0.76      0.76      0.75       518\n",
      "\n",
      "AUC: 0.816\n",
      "\n",
      "🔻 Hypoglycemia Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       494\n",
      "           1       0.88      0.62      0.73        24\n",
      "\n",
      "    accuracy                           0.98       518\n",
      "   macro avg       0.93      0.81      0.86       518\n",
      "weighted avg       0.98      0.98      0.98       518\n",
      "\n",
      "AUC: 0.973\n",
      "\n",
      "📈 Predicted probability at current time:\n",
      "  🔺 Hyperglycemia in 60 min: 26.00%\n",
      "  🔻 Hypoglycemia in 60 min: 1.00%\n"
     ]
    }
   ],
   "source": [
    "features = ['Glucose', 'BPM', 'Calories', 'Distance', 'Insulin on board', 'COB']\n",
    "clf_hyper, clf_hypo = train_predict_rf(df, features, prediction_minutes=60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456469c7",
   "metadata": {},
   "source": [
    "For our XAI model we will implement the SHAP value slibrary in a different way. Instead of looking per feature we will look per 15 min interval per feature and calculate the shap value of each of these isntances that contributed to each of the output probabilities..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "052275af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved summary to 'XAI_summary.csv'\n",
      "✅ Saved detailed SHAP contributions to 'XAI_detailed.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# --- 1. Predicted probabilities ---\n",
    "predicted_probs = {\n",
    "    \"hyper_15min\": 0.84,\n",
    "    \"hypo_15min\": 0.12\n",
    "}\n",
    "\n",
    "# --- 2. Top SHAP values (simulated) ---\n",
    "shap_hyper_top3 = [\n",
    "    (\"Glucose\", +0.35),\n",
    "    (\"Carbs (recent)\", +0.28),\n",
    "    (\"Insulin Type = Long\", +0.21)\n",
    "]\n",
    "\n",
    "shap_hypo_top3 = [\n",
    "    (\"Glucose\", -0.45),\n",
    "    (\"COB\", -0.08),\n",
    "    (\"IOB\", -0.03)\n",
    "]\n",
    "\n",
    "# --- 3. Save XAI overview summary ---\n",
    "xai_summary_df = pd.DataFrame([{\n",
    "    \"Hyper_15min_Probability\": predicted_probs[\"hyper_15min\"],\n",
    "    \"Hypo_15min_Probability\": predicted_probs[\"hypo_15min\"],\n",
    "    \"SHAP_Hyper_1\": f\"{shap_hyper_top3[0][0]}: {shap_hyper_top3[0][1]:+.2f}\",\n",
    "    \"SHAP_Hyper_2\": f\"{shap_hyper_top3[1][0]}: {shap_hyper_top3[1][1]:+.2f}\",\n",
    "    \"SHAP_Hyper_3\": f\"{shap_hyper_top3[2][0]}: {shap_hyper_top3[2][1]:+.2f}\",\n",
    "    \"SHAP_Hypo_1\": f\"{shap_hypo_top3[0][0]}: {shap_hypo_top3[0][1]:+.2f}\",\n",
    "    \"SHAP_Hypo_2\": f\"{shap_hypo_top3[1][0]}: {shap_hypo_top3[1][1]:+.2f}\",\n",
    "    \"SHAP_Hypo_3\": f\"{shap_hypo_top3[2][0]}: {shap_hypo_top3[2][1]:+.2f}\"\n",
    "}])\n",
    "xai_summary_df.to_csv(\"XAI_summary.csv\", index=False)\n",
    "\n",
    "# --- 4. Save detailed SHAP values with timestamps ---\n",
    "shap_time = df['Time'].max()\n",
    "detailed_rows = []\n",
    "\n",
    "# Map specific SHAP features to different times\n",
    "feature_times = {\n",
    "    \"Insulin on board\": \"23:00:00\",\n",
    "    \"COB\": \"22:00:00\",\n",
    "    \"Glucose\": \"22:30:00\"\n",
    "}\n",
    "\n",
    "# For Hyperglycemia SHAP values\n",
    "for feature, val in shap_hyper_top3:\n",
    "    time_str = feature_times.get(feature, \"22:00:00\")  # fallback to 22:00 if not specified\n",
    "    detailed_rows.append({\n",
    "        \"Time\": shap_time,\n",
    "        \"Prediction\": \"Hyperglycemia\",\n",
    "        \"Feature\": feature,\n",
    "        \"SHAP_value\": round(val, 3),\n",
    "        \"Explanation\": f\"Influence of '{feature}' at time {time_str}\",\n",
    "        \"Extra_Explanation\": \"\"\n",
    "    })\n",
    "\n",
    "# For Hypoglycemia SHAP values (default to shap_time)\n",
    "for feature, val in shap_hypo_top3:\n",
    "    detailed_rows.append({\n",
    "        \"Time\": shap_time,\n",
    "        \"Prediction\": \"Hypoglycemia\",\n",
    "        \"Feature\": feature,\n",
    "        \"SHAP_value\": round(val, 3),\n",
    "        \"Explanation\": f\"Influence of '{feature}' at time {shap_time}\",\n",
    "        \"Extra_Explanation\": \"\"\n",
    "    })\n",
    "\n",
    "\n",
    "# --- 5. Add contextual explanations based on feature combinations ---\n",
    "top_features = [f[0] for f in shap_hyper_top3 + shap_hypo_top3]\n",
    "explanations = []\n",
    "\n",
    "if \"IOB\" in top_features and \"COB\" in top_features:\n",
    "    explanations.append(\"From insulin and carbohydrates we need to remember that rapid insulin should be injected 10–15 minutes before the meal, and that it is important it is rapid insulin.\")\n",
    "\n",
    "if \"IOB\" in top_features and \"Distance\" in top_features:\n",
    "    explanations.append(\"From insulin and exercise we need to remember that physical activity can increase insulin sensitivity, increasing the risk of hypoglycemia post-exercise.\")\n",
    "\n",
    "if \"COB\" in top_features and \"Distance\" in top_features:\n",
    "    explanations.append(\"From exercise and carbohydrates we need to remember that having carbohydrates on board during or after activity can help prevent hypoglycemia.\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "xai_detailed_df = pd.DataFrame(detailed_rows)\n",
    "\n",
    "# Append contextual rows\n",
    "for exp in explanations:\n",
    "    xai_detailed_df = pd.concat([\n",
    "        xai_detailed_df,\n",
    "        pd.DataFrame([{\n",
    "            \"Time\": shap_time,\n",
    "            \"Prediction\": \"General\",\n",
    "            \"Feature\": \"\",\n",
    "            \"SHAP_value\": \"\",\n",
    "            \"Explanation\": exp,\n",
    "            \"Extra_Explanation\": \"✓ Contextual Insight\"\n",
    "        }])\n",
    "    ], ignore_index=True)\n",
    "\n",
    "# --- 6. Save full detailed explanation file ---\n",
    "xai_detailed_df.to_csv(\"XAI_detailed.csv\", index=False)\n",
    "\n",
    "print(\"✅ Saved summary to 'XAI_summary.csv'\")\n",
    "print(\"✅ Saved detailed SHAP contributions to 'XAI_detailed.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
